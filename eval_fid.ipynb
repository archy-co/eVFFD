{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_img_files(directory):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if \"png\" in str(file).lower() or \"jpg\" in str(file).lower():\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_img_files(folder_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\"):\n",
    "    real_image_paths = []\n",
    "    generated_image_paths = []\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(real_postfix):\n",
    "            real_image_paths.append(os.path.join(folder_path, file))\n",
    "        elif file.endswith(fake_postfix):\n",
    "            generated_image_paths.append(os.path.join(folder_path, file))\n",
    "    \n",
    "    return sorted(real_image_paths), sorted(generated_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(real_images, generated_images, batch_size=50, device='cpu'):\n",
    "    # Load pre-trained Inception v3 model\n",
    "    inception = models.inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception.eval()\n",
    "\n",
    "    # Resize and normalize images to match Inception v3 requirements\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    def get_features(images):\n",
    "        features = []\n",
    "        with torch.no_grad():\n",
    "            for img in images:\n",
    "                img = transform(img).unsqueeze(0).to(device)\n",
    "                feat = inception(img)[0].view(img.size(0), -1).cpu().numpy()\n",
    "                features.append(feat)\n",
    "        return np.vstack(features)\n",
    "    \n",
    "    # Extract features for real and generated images\n",
    "    real_features = get_features(real_images)\n",
    "    generated_features = get_features(generated_images)\n",
    "    \n",
    "    # Calculate mean and covariance for real and generated features\n",
    "    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu_generated, sigma_generated = np.mean(generated_features, axis=0), np.cov(generated_features, rowvar=False)\n",
    "    \n",
    "    # Calculate FID using the formula:\n",
    "    # FID = ||mu_real - mu_generated||^2 + Tr(sigma_real + sigma_generated - 2 * sqrt(sigma_real * sigma_generated))\n",
    "    diff = mu_real - mu_generated\n",
    "    covmean, _ = sqrtm(sigma_real.dot(sigma_generated), disp=False)\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    fid = diff.dot(diff) + np.trace(sigma_real + sigma_generated - 2 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map2sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 1296.8016\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/map2sat_pretrained_pix2pix/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 1008.9865\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/map2sat_pretrained_CycleGAN/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_A_real.png\", fake_postfix=\"_A_fake.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 1547.2033\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/map2sat_pureUNET/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## facades_label2photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 532.8256\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/facades_label2photo_pretrained_pix2pix/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 1043.1319\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/facades_label2photo_pretrained_CycleGAN/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real.png\", fake_postfix=\"_fake.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 799.9782\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/facades_label2photo_pureUNET/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 612.1227\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/windtunnel_pix2pix/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 655.1222\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/windtunnel_CycleGAN/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_A.png\", fake_postfix=\"_fake_A.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 963.1893\n"
     ]
    }
   ],
   "source": [
    "result_path = \"./results/windtunnel_pureUNET/test_latest/images\"\n",
    "\n",
    "real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_A.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/archy/Documents/LNU/dyplomna/CycleGAN_and_pix2pix_clean_orig/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/archy/Documents/LNU/dyplomna/CycleGAN_and_pix2pix_clean_orig/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Non-matrix input to matrix function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mopen(image_path) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m generated_image_paths]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate FID score\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m fid_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFID score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mcalculate_fid\u001b[0;34m(real_images, generated_images, batch_size, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate FID using the formula:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# FID = ||mu_real - mu_generated||^2 + Tr(sigma_real + sigma_generated - 2 * sqrt(sigma_real * sigma_generated))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m diff \u001b[38;5;241m=\u001b[39m mu_real \u001b[38;5;241m-\u001b[39m mu_generated\n\u001b[0;32m---> 33\u001b[0m covmean, _ \u001b[38;5;241m=\u001b[39m \u001b[43msqrtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_real\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_generated\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39miscomplexobj(covmean):\n\u001b[1;32m     36\u001b[0m     covmean \u001b[38;5;241m=\u001b[39m covmean\u001b[38;5;241m.\u001b[39mreal\n",
      "File \u001b[0;32m~/Documents/LNU/dyplomna/CycleGAN_and_pix2pix_clean_orig/venv/lib/python3.9/site-packages/scipy/linalg/_matfuncs_sqrtm.py:169\u001b[0m, in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    167\u001b[0m A \u001b[38;5;241m=\u001b[39m _asarray_validated(A, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, as_inexact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-matrix input to matrix function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocksize \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe blocksize should be at least 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Non-matrix input to matrix function."
     ]
    }
   ],
   "source": [
    "# result_path = \"./results/windtunnel_pureUNET/test_latest/images\"\n",
    "# real_image_paths, generated_image_paths = list_all_img_files(result_path, real_postfix=\"_real_B.png\", fake_postfix=\"_fake_B.png\")\n",
    "\n",
    "real_image_paths = [\"experimental/windtunnel_20240415_125028_real_B.png\"]\n",
    "generated_image_paths = [\"experimental/windtunnel_20240415_125028_real_B_gray.png\"]\n",
    "\n",
    "generated_image_paths = real_image_paths[::2]\n",
    "\n",
    "real_images = [Image.open(image_path) for image_path in real_image_paths]\n",
    "generated_images = [Image.open(image_path) for image_path in generated_image_paths]\n",
    "\n",
    "# Calculate FID score\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(f'FID score: {fid_score:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
